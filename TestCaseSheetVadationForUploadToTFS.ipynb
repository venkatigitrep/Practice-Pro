{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 17 19:37:14 2020\n",
    "\n",
    "@author: venkati.naidu\n",
    "\n",
    "The code is to read excel as input, identify the all sheets in excel and then row count\n",
    "Validating the test cases by its mandatory fields\n",
    "Enhancements:\n",
    "1. One column \"Title\" should not more than 256 char width. System is validating the width to be displayed in the report. So that user can minimize the upload failures.\n",
    "2. Find out whether all mandatory columns contains data for each test case\n",
    "3. Will identify the Mandatory columns which are missing from input excel\n",
    "4. All work sheets will be merged into a main sheet\n",
    "\n",
    "To Be Done:\n",
    "1. Validation if input file exist\n",
    "2. Verify wheather all files closed\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#print(\"D&A_ PG1\")\n",
    "#df1 = pd.read_excel (r'C:\\Users\\venkati.naidu\\hello\\Test Cases_CMP_April Release.xlsx', sheet_name='D&A_ PG1', usecols=['Test case Title','Area Path','Iteration Path','Initiative','Application','Priority'])\n",
    "#print (df1.count())\n",
    "#help(\"modules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to specify fields from excel\n",
    "source_filename = \"907028 Dual Purpose DR_TFS Upload\"\n",
    "file_path = r\"C:\\\\Users\\\\venkati.naidu\\\\hello\\\\Coursera\\\\PytonMaterial\\\\ML\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the excel file from the project directory\n",
    "excel_file = r'' + file_path + source_filename +'.xlsx'\n",
    "final_excel = r'' + file_path + source_filename +'_merged.xlsx'\n",
    "if not os.path.isfile(excel_file):\n",
    "       print(\"File path {} does not exist. Exiting...\".format(excel_file))\n",
    "       sys.exit()\n",
    "else:\n",
    "    xlsx = pd.ExcelFile(excel_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Columns to be included/validated in the report\n",
    "\"\"\"\n",
    "#usecols_mandatory=['Title','Area Path','Iteration Path','Initiative','Priority','Bundle']\n",
    "usecols_mandatory=['Title','Area Path','Iteration Path','Initiative','Priority','Bundle','Application']\n",
    "#usecols_mandatory=['Title','Area Path','Iteration Path','Initiative','Priority']\n",
    "usecols_for_report=['Title', 'Area Path', 'Iteration Path','Priority', 'Action', 'Expected Result', 'Initiative','Bundle', 'Application']\n",
    "#usecols_for_report=['Title', 'Area Path', 'Iteration Path','Priority', 'Action', 'Expected Result', 'Initiative']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Below function is to verify the each field count is equal or not\n",
    "\"\"\"\n",
    "\n",
    "def check_tc_count(dfdict_param):\n",
    "        tc_count = True\n",
    "        old_value = 0;\n",
    "        i = 0\n",
    "        for key, value in dfdict_param.items(): \n",
    "         \n",
    "            new_value = value\n",
    "            if old_value == 0 and i == 0:\n",
    "                i+=1\n",
    "                old_value = new_value\n",
    "            elif old_value == new_value:\n",
    "                continue\n",
    "            else:\n",
    "                tc_count = False\n",
    "                break\n",
    "        return tc_count \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Find the lengthy columns if any (i.e. > 250 chars)\"\"\"\n",
    "\n",
    "def found_lengthy_columns(use_case):\n",
    "    df_lengthy_column = use_case[use_case[\"Title Length\"]>256]\n",
    "    if len(df_lengthy_column['Title'])>0:\n",
    "        print(\"Title is too long:\")\n",
    "        print(df_lengthy_column['Title'],df_lengthy_column['Title Length'])\n",
    "        #print (\"{} {}\".format(df_lengthy_column['Title'], df_lengthy_column['Title Length']))\n",
    "        return True\n",
    "    return False   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_missed_mandatory_columns = []\n",
    "\n",
    "def found_missing_mandatory_columns(sheet):\n",
    "    from functools import reduce\n",
    "    twolists=[]\n",
    "    twolists.append(usecols_mandatory)\n",
    "    twolists.append(df.columns.tolist())\n",
    "    #print(f\"Mandatory Columns:\\n{usecols_mandatory}\\n\")\n",
    "    #print(f\"Columns from Sheet:{sheet}:\\n{df.columns.tolist()}\\n\")\n",
    "    #print(f\"Both Mandatory and Columns from sheet:\\n{twolists}\\n\")\n",
    "    \n",
    "    commonlist = list(reduce(lambda i, j: i & j, (set(x) for x in twolists)))\n",
    "    #print(f\"Common element extraction form N lists:\\n{commonlist}\" )\n",
    "    missed_mandatory_columns = [i for i in usecols_mandatory if i not in commonlist]\n",
    "    ##print(f\"Missed Mandatory Columns in Excel Sheet:\\n{missed_mandatory_columns}\" )\n",
    "    \n",
    "    if len(missed_mandatory_columns) > 0:\n",
    "        print(f\"Missed Mandatory Columns in Excel Sheet: {sheet}\\n{missed_mandatory_columns}\" )\n",
    "        check_missed_mandatory_columns.append(True)\n",
    "        return True\n",
    "    else:\n",
    "        #print(\"No mismatches\")\n",
    "        return False\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#boolean = not df[\"Student\"].is_unique      # True (credit to @Carsten)\n",
    "#boolean = df['Student'].duplicated().any() # True\n",
    "def found_mismatch_area_iteration(use_case):\n",
    "    list_areas = use_case[\"Area Path\"].unique().tolist()\n",
    "    list_iterations = use_case[\"Iteration Path\"].unique().tolist()\n",
    "    list_areas = [area for area in list_areas if str(area) != 'nan']\n",
    "    list_iterations = [iteration for iteration in list_iterations if str(iteration) != 'nan']\n",
    "    #print('list_areas',list_areas_count)\n",
    "    #print('list_iteration',list_iterations_count)\n",
    "    if len(list_areas)>1:\n",
    "        print(\"Found Discrepancy in Area Path:\")\n",
    "        print(\"*\"*15)\n",
    "        for area in list_areas:\n",
    "            print(area) \n",
    "        return True\n",
    "    elif len(list_iterations)>1:\n",
    "        print(\"Found Discrepancy in Iteration Path:\")\n",
    "        print(\"*\"*15)\n",
    "        for iteration in list_iterations:\n",
    "            print(iteration) \n",
    "        return True\n",
    "    return False   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Report will be Printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "907028_Dual Purpose DR  : PASS - Mandatory fields exist for all test cases\n",
      "***************\n",
      "{'Title': 107, 'Area Path': 107, 'Iteration Path': 107, 'Initiative': 107, 'Priority': 107, 'Bundle': 107, 'Application': 107}\n",
      "----------------------------------------------------------------------\n",
      "######################################################################\n",
      "Merged All Spread Sheets in a main Excel File:\n",
      " C:\\\\Users\\\\venkati.naidu\\\\hello\\\\Coursera\\\\PytonMaterial\\\\ML\\\\907028 Dual Purpose DR_TFS Upload_merged.xlsx\n",
      "######################################################################\n"
     ]
    }
   ],
   "source": [
    "cannot_merge_excel = [] # list of xl sheets\n",
    "\n",
    "all_sheets = pd.DataFrame()\n",
    "for sheet in xlsx.sheet_names:\n",
    "\n",
    "    df = xlsx.parse(sheet)\n",
    "    #print(sheet)\n",
    "    \"\"\"\n",
    "    Adding column names\n",
    "    \"\"\"\n",
    "  \n",
    "    \n",
    "    if not found_missing_mandatory_columns(sheet):\n",
    "        #print(\"Proceed with Testing\")\n",
    "    \n",
    "        df_report = df[usecols_for_report]\n",
    "        df = df[usecols_mandatory]\n",
    "    \n",
    "        \"\"\"\n",
    "        Counting the columns and storing the each field and respective row count in respective field\n",
    "        \"\"\"\n",
    "        dfdict = dict(df.count())\n",
    "        #print(\"print df\",df.shape)\n",
    "        #print(dfdict)\n",
    "    \n",
    "        \"\"\"\n",
    "        Following code will print the Usecase name (Sheet name) after field validation\n",
    "        \"\"\"\n",
    "        df[\"Title Length\"]= df[\"Title\"].str.len()\n",
    "        #p+=1\n",
    "        \n",
    "        if check_tc_count(dfdict): # and not found_mismatch_area_iteration(df):\n",
    "            print('-' * 70)\n",
    "            print(sheet,\" : PASS - Mandatory fields exist for all test cases\")\n",
    "            print(\"*\"*15)\n",
    "            print(dfdict)\n",
    "            all_sheets =pd.concat([all_sheets, df_report],ignore_index=True)\n",
    "            cannot_merge_excel.append(found_lengthy_columns(df)) # print test case title if it is too long\n",
    "            cannot_merge_excel.append(found_mismatch_area_iteration(df))\n",
    "            \n",
    "            print('-' * 70)\n",
    "            all_sheets.append(df_report, ignore_index=True)       \n",
    "        else:\n",
    "            \"\"\"\n",
    "            Print the fields and respective row count if the validation failed\n",
    "            \"\"\"\n",
    "            print('-' * 70)\n",
    "            print(sheet,\" : Test Case FIELD COUNT is NOT matching as below:\")\n",
    "            print('-' * 70)\n",
    "            print (\"{:<20} {:<20} \".format('Column Title', 'Row Count')) \n",
    "            for key, value in dfdict.items():\n",
    "                print (\"{:<25} {:<25} \".format(key, value))\n",
    "            cannot_merge_excel.append(True)  ## if field count is not matching\n",
    "\n",
    "\n",
    "if  cannot_merge_excel.count(True) > 0 or len(check_missed_mandatory_columns)>0 :\n",
    "    print('#' * 70)\n",
    "    print(\"Please fix the issue in Excel and come again\")\n",
    "    print('#' * 70)\n",
    "else: # len(check_missed_mandatory_columns)>0:\n",
    "    all_sheets.reindex()\n",
    "    #Data Cleanup\n",
    "    all_sheets = all_sheets.loc[:, ~all_sheets.columns.str.contains('^Unnamed')] # dropping unnamed columns\n",
    "    #all_sheets = all_sheets.drop(all_sheets.columns[[0]], axis=1) # drop first 2 columns\n",
    "    all_sheets = all_sheets.dropna(thresh=1) #Drop row if it does not have at least two values that are **not** NaN\n",
    "    #Convert data frame to excel sheet\n",
    "    all_sheets.to_excel(final_excel, index = False)\n",
    "    all_sheets.head(10)\n",
    "    print('#' * 70)\n",
    "    print(\"Merged All Spread Sheets in a main Excel File:\\n\", final_excel)\n",
    "    print('#' * 70)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "This code will import all excel files from the current directory\n",
    "ref:https://pythoninoffice.com/use-python-to-combine-multiple-excel-files/\n",
    "import os\n",
    "import pandas as pd\n",
    "cwd = os.path.abspath('') \n",
    "files = os.listdir(cwd)  \n",
    "df = pd.DataFrame()\n",
    "for file in files:\n",
    "    if file.endswith('.xlsx'):\n",
    "        df = df.append(pd.read_excel(file), ignore_index=True) \n",
    "df.head() \n",
    "df.to_excel('total_sales.xlsx')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
